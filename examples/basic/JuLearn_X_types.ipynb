{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpvPVf9Xu5rI"
      },
      "source": [
        "# **Customize your pipeline**\n",
        "\n",
        "In this example, we'll look at how you can individualize single analysis steps by assigning \n",
        "a \"type\" to a column (`X_types`), using the `penguins` example dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rPNNfex-0U-A"
      },
      "outputs": [],
      "source": [
        "# Authors: Vincent KÃ¼ppers <v.kueppers@fz-juelich.de>\n",
        "#          Hanwen Bi <h.bi@fz-juelich.de>\n",
        "#          \n",
        "# \n",
        "# License: AGPL\n",
        "\n",
        "from seaborn import load_dataset\n",
        "from julearn.pipeline import PipelineCreator\n",
        "from julearn import run_cross_validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sM4TVYmf0UOo"
      },
      "source": [
        "Load dataset, remove rows with missing values   \n",
        "define features + target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "awXTaNde0gsW"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>species</th>\n",
              "      <th>island</th>\n",
              "      <th>bill_length_mm</th>\n",
              "      <th>bill_depth_mm</th>\n",
              "      <th>flipper_length_mm</th>\n",
              "      <th>body_mass_g</th>\n",
              "      <th>sex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>39.1</td>\n",
              "      <td>18.7</td>\n",
              "      <td>181.0</td>\n",
              "      <td>3750.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>39.5</td>\n",
              "      <td>17.4</td>\n",
              "      <td>186.0</td>\n",
              "      <td>3800.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>40.3</td>\n",
              "      <td>18.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>3250.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>36.7</td>\n",
              "      <td>19.3</td>\n",
              "      <td>193.0</td>\n",
              "      <td>3450.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>39.3</td>\n",
              "      <td>20.6</td>\n",
              "      <td>190.0</td>\n",
              "      <td>3650.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
              "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
              "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
              "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
              "3  Adelie  Torgersen            36.7           19.3              193.0   \n",
              "4  Adelie  Torgersen            39.3           20.6              190.0   \n",
              "\n",
              "   body_mass_g  sex  \n",
              "0       3750.0    2  \n",
              "1       3800.0    1  \n",
              "2       3250.0    1  \n",
              "3       3450.0    1  \n",
              "4       3650.0    2  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_penguins = load_dataset(\"penguins\")\n",
        "df_penguins = df_penguins.dropna().reset_index(drop=True)\n",
        "df_penguins = df_penguins.replace({\"sex\": {\"Female\": 1, \"Male\": 2}})\n",
        "\n",
        "df_penguins.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xzRVhiMX4SOD"
      },
      "outputs": [],
      "source": [
        "X = df_penguins.iloc[:,2:,].columns.tolist()\n",
        "y = \"species\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-2cn7wI0gzx"
      },
      "source": [
        "Define custom types for columns (of input features, X).  \n",
        "We will use those types in the `PipelineCreator` to specify input.  \n",
        "To adress all features in the `PipelineCreator` use `*`.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEBU4JfE926P"
      },
      "source": [
        "! Important: if you define X types, you also need to be specific with `apply_to`. In the PipelineCreator you can set to which features your model (here `svm`) is applied to. If no input is given, all processing steps (including the final model) are applied to all *non* defined features (i.e. `continuous`). By default PCA output is of type:`continuous`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lV_kghdhic1m"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    1.000000\n",
            "1    0.940299\n",
            "2    0.850746\n",
            "3    0.969697\n",
            "4    1.000000\n",
            "Name: test_score, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "X_types = {\n",
        "    \"bill\": [\"bill_length_mm\", \"bill_depth_mm\"],\n",
        "    \"body\": [\"flipper_length_mm\", \"body_mass_g\"],\n",
        "    \"our_confound\": [\"sex\"]\n",
        "}\n",
        "\n",
        "creator_1 = PipelineCreator(problem_type=\"classification\", apply_to=\"*\")\n",
        "\n",
        "creator_1.add(\"zscore\", apply_to=\"*\")\n",
        "creator_1.add(\"pca\", apply_to=[\"bill\"], n_components=1)\n",
        "creator_1.add(\"svm\")\n",
        "\n",
        "scores_1, model_1 = run_cross_validation(\n",
        "            X=X, y=y, data=df_penguins, \n",
        "            X_types = X_types,\n",
        "            model = creator_1, \n",
        "            return_estimator=\"final\"\n",
        ")\n",
        "print(scores_1['test_score'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bwg59ZVk0vH7"
      },
      "source": [
        "We can also z-score by the X_types defined before. Additionally we will `minmaxscale` other variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ADs3Z18pzCiv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    1.000000\n",
            "1    0.985075\n",
            "2    0.910448\n",
            "3    0.984848\n",
            "4    1.000000\n",
            "Name: test_score, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "creator_2 = PipelineCreator(problem_type=\"classification\", apply_to=\"*\")\n",
        "\n",
        "creator_2.add(\"zscore\", apply_to=\"bill\")\n",
        "creator_2.add(\"scaler_minmax\", apply_to=\"body\")\n",
        "creator_2.add(\"remove_confound\", apply_to=[\"bill\", \"body\"], confounds=[\"our_confound\"])\n",
        "creator_2.add(\"svm\")\n",
        "\n",
        "scores_2, model_2 = run_cross_validation(\n",
        "            X=X, y=y, data=df_penguins, \n",
        "            X_types = X_types,\n",
        "            model = creator_2, \n",
        "            return_estimator=\"final\"\n",
        ")\n",
        "print(scores_2['test_score'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-X-J5Yb2znR4"
      },
      "source": [
        "Now, let's compare both preprocessing pipelines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "4nJwFBNCyylF",
        "outputId": "627742ce-39b4-489f-cac5-e3dfa512793f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on function preprocess in module julearn.inspect.preprocess:\n",
            "\n",
            "preprocess(pipeline, X, data, until=None, with_column_types=False)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from julearn.inspect import preprocess\n",
        "help(preprocess)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By setting the parameter `until=` to pipeline step, you can track how the variables were transformed until that step (including)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "EFMArnqn3s9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "variables before pipeline \n",
            "    bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g  sex\n",
            "0            39.1           18.7              181.0       3750.0    2\n",
            "1            39.5           17.4              186.0       3800.0    1\n",
            "2            40.3           18.0              195.0       3250.0    1\n",
            "3            36.7           19.3              193.0       3450.0    1\n",
            "4            39.3           20.6              190.0       3650.0    2\n",
            "variables after zscore \n",
            "    bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g       sex\n",
            "0       -0.896042       0.780732          -1.426752    -0.568475  0.991031\n",
            "1       -0.822788       0.119584          -1.069474    -0.506286 -1.009050\n",
            "2       -0.676280       0.424729          -0.426373    -1.190361 -1.009050\n",
            "3       -1.335566       1.085877          -0.569284    -0.941606 -1.009050\n",
            "4       -0.859415       1.747026          -0.783651    -0.692852  0.991031\n",
            "variables after pca \n",
            "        pca0  flipper_length_mm  body_mass_g       sex\n",
            "0  1.185658          -1.426752    -0.568475  0.991031\n",
            "1  0.666358          -1.069474    -0.506286 -1.009050\n",
            "2  0.778531          -0.426373    -1.190361 -1.009050\n",
            "3  1.712219          -0.569284    -0.941606 -1.009050\n",
            "4  1.843032          -0.783651    -0.692852  0.991031\n"
          ]
        }
      ],
      "source": [
        "print('variables before pipeline \\n', df_penguins[X].head())\n",
        "print('variables after zscore \\n', preprocess(model_1, X, df_penguins, until='zscore').head())\n",
        "print('variables after pca \\n', preprocess(model_1, X, df_penguins, until='pca').head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also see how it looks like after remove confounds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "variables before pipeline \n",
            "    bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g  sex\n",
            "0            39.1           18.7              181.0       3750.0    2\n",
            "1            39.5           17.4              186.0       3800.0    1\n",
            "2            40.3           18.0              195.0       3250.0    1\n",
            "3            36.7           19.3              193.0       3450.0    1\n",
            "4            39.3           20.6              190.0       3650.0    2\n",
            "variables after zscore \n",
            "    bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g  sex\n",
            "0       -0.896042       0.780732              181.0       3750.0  2.0\n",
            "1       -0.822788       0.119584              186.0       3800.0  1.0\n",
            "2       -0.676280       0.424729              195.0       3250.0  1.0\n",
            "3       -1.335566       1.085877              193.0       3450.0  1.0\n",
            "4       -0.859415       1.747026              190.0       3650.0  2.0\n",
            "variables after pca \n",
            "    flipper_length_mm  body_mass_g  bill_length_mm  bill_depth_mm\n",
            "0          -0.398406    -0.221023       -1.237034       0.411401\n",
            "1          -0.192604    -0.017298       -0.475596       0.495630\n",
            "2          -0.040062    -0.170076       -0.329088       0.800775\n",
            "3          -0.073960    -0.114520       -0.988374       1.461923\n",
            "4          -0.245864    -0.248801       -1.200407       1.377695\n"
          ]
        }
      ],
      "source": [
        "print('variables before pipeline \\n', df_penguins[X].head())\n",
        "print('variables after zscore \\n', preprocess(model_2, X, df_penguins, until='zscore').head())\n",
        "print('variables after pca \\n', preprocess(model_2, X, df_penguins, until='remove_confound').head())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.15 ('julearn_hackaton')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "0efeb6f3462ec810b7f8bbbb58d315c051be1238024ab9b06e1324440b93dfbc"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
